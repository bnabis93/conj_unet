{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python\n",
    "#import module for predict\n",
    "import os\n",
    "import numpy as np\n",
    "import configparser\n",
    "import cv2\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "#Keras\n",
    "sys.path.insert(0, './lib/')\n",
    "# help_functions.py\n",
    "from help_functions import *\n",
    "# extract_patches.py\n",
    "from extract_patches import *\n",
    "# pre_processing.py\n",
    "from pre_processing import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = './conj_data/'\n",
    "def width_padding(img, pad_size):\n",
    "    h,w = np.shape(img)\n",
    "    #print('pad size', pad_size)\n",
    "    \n",
    "    if pad_size % 2 ==1: #odd number\n",
    "        pad01 = np.zeros((h, pad_size//2))\n",
    "        pad02 = np.zeros((h, pad_size//2 +1))\n",
    "    \n",
    "        result = np.hstack([pad01, img])\n",
    "        result = np.hstack([result, pad02])\n",
    "        \n",
    "    else:\n",
    "        pad01 = np.zeros((h, pad_size//2))\n",
    "    \n",
    "        result = np.hstack([pad01, img])\n",
    "        result = np.hstack([result, pad01])\n",
    "        \n",
    "    print(np.shape(img), ' ',np.shape(result))\n",
    "    return result\n",
    "    \n",
    "def height_padding(img,pad_size):\n",
    "    h,w = np.shape(img)\n",
    "    #print('pad size : ',pad_size)\n",
    "    \n",
    "    if pad_size % 2 ==1: #odd number\n",
    "        pad01 = np.zeros((pad_size//2,w ))\n",
    "        pad02 = np.zeros((pad_size//2 +1 , w))\n",
    "        \n",
    "        result = np.vstack([pad01, img])\n",
    "        result = np.vstack([result,pad02])\n",
    "        \n",
    "    else:\n",
    "        pad01 = np.zeros((pad_size//2, w))\n",
    "    \n",
    "        result = np.vstack([pad01, img])\n",
    "        result = np.vstack([result, pad01])\n",
    "    print(np.shape(img), ' ',np.shape(result))\n",
    "    return result\n",
    "\n",
    "    patches_imgs_test = extract_ordered(test_imgs,patch_h,patch_w)\n",
    "    #data_consistency_check(test_imgs, test_grds)\n",
    "\n",
    "    print (\"\\n[get_data_testing_fucn] test PATCHES images/grds shape:\")\n",
    "    print (patches_imgs_test.shape)\n",
    "    print (\"[get_data_testing_fucn] test PATCHES images range (min-max): {} - {}\".format(str(np.min(patches_imgs_test)), str(np.max(patches_imgs_test))))\n",
    "\n",
    "    return patches_imgs_test\n",
    "\n",
    "def width_avg_padding(img, pad_size):\n",
    "    h,w = np.shape(img)\n",
    "    #print('pad size', pad_size)\n",
    "    avg_val = np.mean(img)\n",
    "    \n",
    "    if pad_size % 2 ==1: #odd number\n",
    "        pad01 = np.full((h, pad_size//2),avg_val)\n",
    "        pad02 = np.full((h, pad_size//2 +1),avg_val)\n",
    "    \n",
    "        result = np.hstack([pad01, img])\n",
    "        result = np.hstack([result, pad02])\n",
    "        \n",
    "    else:\n",
    "        pad01 = np.full((h, pad_size//2),avg_val)\n",
    "    \n",
    "        result = np.hstack([pad01, img])\n",
    "        result = np.hstack([result, pad01])\n",
    "        \n",
    "    print(np.shape(img), ' ',np.shape(result))\n",
    "    return result\n",
    "    \n",
    "def height_avg_padding(img,pad_size):\n",
    "    h,w = np.shape(img)\n",
    "    #print('pad size : ',pad_size)\n",
    "    avg_val = np.mean(img)\n",
    "    if pad_size % 2 ==1: #odd number\n",
    "        pad01 = np.full((pad_size//2,w ),avg_val)\n",
    "        pad02 = np.full((pad_size//2 +1 , w),avg_val)\n",
    "        \n",
    "        result = np.vstack([pad01, img])\n",
    "        result = np.vstack([result,pad02])\n",
    "        \n",
    "    else:\n",
    "        pad01 = np.full((pad_size//2, w),avg_val)\n",
    "    \n",
    "        result = np.vstack([pad01, img])\n",
    "        result = np.vstack([result, pad01])\n",
    "    print(np.shape(img), ' ',np.shape(result))\n",
    "    return result\n",
    "\n",
    "    patches_imgs_test = extract_ordered(test_imgs,patch_h,patch_w)\n",
    "    #data_consistency_check(test_imgs, test_grds)\n",
    "\n",
    "    print (\"\\n[get_data_testing_fucn] test PATCHES images/grds shape:\")\n",
    "    print (patches_imgs_test.shape)\n",
    "    print (\"[get_data_testing_fucn] test PATCHES images range (min-max): {} - {}\".format(str(np.min(patches_imgs_test)), str(np.max(patches_imgs_test))))\n",
    "\n",
    "    return patches_imgs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "[[ 0.  0.  0.]\n",
      " [ 8.  4.  2.]\n",
      " [ 3. 15. 11.]\n",
      " [ 9.  3.  1.]]\n",
      "[[ 6  6  6]\n",
      " [ 8  4  2]\n",
      " [ 3 15 11]\n",
      " [ 9  3  1]]\n"
     ]
    }
   ],
   "source": [
    "pad_size = 2\n",
    "h= [[8,4,2],[3,15,11],[9,3,1]]\n",
    "h = np.asarray(h, dtype='uint8')\n",
    "print(np.shape(h))\n",
    "pad01 = np.zeros((int(pad_size//2),3))\n",
    "result = np.vstack([pad01, h])\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "avg_val = int(np.mean(h))\n",
    "pad01 = np.full((int(pad_size//2),3),avg_val)\n",
    "result = np.vstack([pad01, h])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(423, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(536, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(530, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(342, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(558, 546)   (558, 565)\n",
      "(558, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(497, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(480, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(388, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(380, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(459, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(571, 540)   (571, 565)\n",
      "(571, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(558, 549)   (558, 565)\n",
      "(558, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(578, 538)   (578, 565)\n",
      "(578, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(587, 522)   (587, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(546, 548)   (546, 565)\n",
      "(546, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(581, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(472, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(463, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(380, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(581, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(396, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(551, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(445, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(549, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(512, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(565, 507)   (565, 565)\n",
      "(565, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(463, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "(453, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n",
      "already exist the folder in this path : ./conj_train\n",
      "[WHAT THE FUCK] (584, 565)\n"
     ]
    }
   ],
   "source": [
    "# 1. image size 조절 (DRIVE와 같은 크기로 하자)\n",
    "# 2. image 크기가 작은 경우, 평균값으로 배경을 채운다.\n",
    "# 3. image 크기가 큰 경우, 여러 조각으로 나누어 데이터 수를 증가시킨다.\n",
    "\n",
    "# DRIVE image information\n",
    "# img_height = 584\n",
    "# img_width = 565\n",
    "\n",
    "# 사이즈만 맞춰서 특정 폴더에 넣어버리\n",
    "\n",
    "    \n",
    "def conj_img_size_preprocessing(data_path):\n",
    "    DRIVE_height = 584\n",
    "    DRIVE_width = 565\n",
    "    \n",
    "    \n",
    "    cnt = 1\n",
    "    \n",
    "    for path, subdirs, files in os.walk(data_path): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            tempImg = cv2.imread(data_path + files[i])\n",
    "  \n",
    "            if (len(np.shape(tempImg)) >2 ):\n",
    "                tempImg =  tempImg[:,:,1]\n",
    "            \n",
    "            h, w = tempImg.shape\n",
    "           \n",
    "            if (w < DRIVE_width):\n",
    "                pad_size = DRIVE_width - w\n",
    "\n",
    "                tempImg = width_padding(tempImg, pad_size)\n",
    "                \n",
    "            elif (w > DRIVE_width):\n",
    "                # 대충 crop하자\n",
    "                tempImg = tempImg[:, : DRIVE_width]      \n",
    "            else:\n",
    "                pass\n",
    "                #print(\"conj width == DRIVE_width\")\n",
    "\n",
    "                \n",
    "            if (h < DRIVE_height):\n",
    "                pad_size = DRIVE_height - h\n",
    "                tempImg = height_padding(tempImg, pad_size)\n",
    "                \n",
    "            elif (h > DRIVE_height):\n",
    "                tempImg = tempImg[: DRIVE_height, :]\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "                #print(\"conj height ==  DRIVE_height\")\n",
    "            \n",
    "                \n",
    "            if os.path.isdir('./conj_train') == False:\n",
    "                os.mkdir('./conj_train')\n",
    "            else:\n",
    "                print('already exist the folder in this path : {}'.format('./conj_train'))\n",
    "            \n",
    "            #print('[WHAT THE FUCK]', np.shape(tempImg))\n",
    "            cv2.imwrite('./conj_train/'+'/train_data_'+str(cnt)+'.png', tempImg)\n",
    "            cnt = cnt+1\n",
    "            \n",
    "    \n",
    "\n",
    "conj_img_size_preprocessing(path_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(423, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(536, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(530, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(342, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(558, 546)   (558, 565)\n",
      "(558, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(497, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(480, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(388, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(380, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(459, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(571, 540)   (571, 565)\n",
      "(571, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(558, 549)   (558, 565)\n",
      "(558, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(578, 538)   (578, 565)\n",
      "(578, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(587, 522)   (587, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(546, 548)   (546, 565)\n",
      "(546, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(581, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(472, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(463, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(380, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(581, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(396, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(551, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(445, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(549, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(512, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(565, 507)   (565, 565)\n",
      "(565, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(463, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "(453, 565)   (584, 565)\n",
      "already exist the folder in this path : ./conj_train_avg\n",
      "already exist the folder in this path : ./conj_train_avg\n"
     ]
    }
   ],
   "source": [
    "# 1. image size 조절 (DRIVE와 같은 크기로 하자)\n",
    "# 2. image 크기가 작은 경우, 평균값으로 배경을 채운다.\n",
    "# 3. image 크기가 큰 경우, 여러 조각으로 나누어 데이터 수를 증가시킨다.\n",
    "\n",
    "# DRIVE image information\n",
    "# img_height = 584\n",
    "# img_width = 565\n",
    "\n",
    "# 사이즈만 맞춰서 특정 폴더에 넣어버리\n",
    "\n",
    "    \n",
    "def conj_img_size_avg_preprocessing(data_path):\n",
    "    DRIVE_height = 584\n",
    "    DRIVE_width = 565\n",
    "    \n",
    "    \n",
    "    cnt = 1\n",
    "    \n",
    "    for path, subdirs, files in os.walk(data_path): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            tempImg = cv2.imread(data_path + files[i])\n",
    "  \n",
    "            if (len(np.shape(tempImg)) >2 ):\n",
    "                tempImg =  tempImg[:,:,1]\n",
    "            \n",
    "            h, w = tempImg.shape\n",
    "           \n",
    "            if (w < DRIVE_width):\n",
    "                pad_size = DRIVE_width - w\n",
    "\n",
    "                tempImg = width_avg_padding(tempImg, pad_size)\n",
    "                \n",
    "            elif (w > DRIVE_width):\n",
    "                # 대충 crop하자\n",
    "                tempImg = tempImg[:, : DRIVE_width]      \n",
    "            else:\n",
    "                pass\n",
    "                #print(\"conj width == DRIVE_width\")\n",
    "\n",
    "                \n",
    "            if (h < DRIVE_height):\n",
    "                pad_size = DRIVE_height - h\n",
    "                tempImg = height_avg_padding(tempImg, pad_size)\n",
    "                \n",
    "            elif (h > DRIVE_height):\n",
    "                tempImg = tempImg[: DRIVE_height, :]\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "                #print(\"conj height ==  DRIVE_height\")\n",
    "            \n",
    "                \n",
    "            if os.path.isdir('./conj_train_avg') == False:\n",
    "                os.mkdir('./conj_train_avg')\n",
    "            else:\n",
    "                print('already exist the folder in this path : {}'.format('./conj_train_avg'))\n",
    "            \n",
    "            #print('[WHAT THE FUCK]', np.shape(tempImg))\n",
    "            cv2.imwrite('./conj_train_avg/'+'/train_data_'+str(cnt)+'.png', tempImg)\n",
    "            cnt = cnt+1\n",
    "            \n",
    "    \n",
    "\n",
    "conj_img_size_avg_preprocessing(path_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./conj_data/\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n",
      "(584, 565)\n"
     ]
    }
   ],
   "source": [
    "HEIGHT_IMG = 584\n",
    "WIDTH_IMG = 565\n",
    "NUM_IMG = 0\n",
    "CONJ_IMG_LIST = []\n",
    "\n",
    "print(path_data)\n",
    "\n",
    "for path, subdirs, files in os.walk('./conj_train/'): #list all files, directories in the path\n",
    "        for i in range(len(files)):\n",
    "            tempImg = cv2.imread('./conj_train/' + files[i], 0)\n",
    "            print(np.shape(tempImg))\n",
    "            CONJ_IMG_LIST.append(tempImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mask\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
