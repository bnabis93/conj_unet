[data paths]
conj_path_local =  ./conj_train/


[experiment name]
name = conjunctival_test_norm_150000


[data attributes]
#Dimensions of the patches extracted from the full images
patch_height = 48
patch_width = 48


[training settings]
#number of total patches:
#num_subimgs = 50000

#if patches are extracted only inside the field of view:
#inside_FOV = False

#Number of training epochs
num_epochs = 150
batch_size = 32

#if running with nohup
nohup = True


[testing settings]
#Choose the model to test: best==epoch with min loss, last==last epoch 
experiment_target = DRIVE_test_norm_150000

best_last = best

#number of full images for the test (max 20, DRIVE datasets)
full_images_to_test = 20

#How many original-groundTruth-prediction images are visualized in each image
num_group_visual = 1

#Compute average in the prediction, improve results but require more patches to be predicted
average_mode = True
#Only if average_mode==True. Stride for patch extraction, lower value require more patches to be predicted
stride_height = 5
stride_width = 5
#if running with nohup
nohup = False
